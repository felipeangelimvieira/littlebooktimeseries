# Modelos de Machine Learning

```{python}
from tsbook.datasets.retail import SyntheticRetail
from sktime.utils.plotting import plot_series
from sktime.forecasting.naive import NaiveForecaster

dataset = SyntheticRetail("univariate")
y_train, X_train, y_test, X_test = dataset.load(
    "y_train", "X_train", "y_test", "X_test"
)

X_train
```


```{python}
from tsbook.forecasting.reduction import ReductionForecaster
from sklearn.ensemble import RandomForestRegressor
from sktime.transformations.series.difference import Differencer

regressor = RandomForestRegressor(n_estimators=100, random_state=42)
model = Differencer() * ReductionForecaster(
    regressor,
    window_length=30,
    steps_ahead=1,
)

model.fit(y_train, X=X_train)
y_pred = model.predict(fh=y_test.index, X=X_test)
```

```{python}
plot_series(
    y_train, y_test, y_pred, labels=["Treino", "Teste", "Previsão com ML + Diferença"]
)
```


```{python}

import numpy as np
from typing import Callable, Tuple

def mean_window_normalizer(window: np.ndarray) -> Tuple[
    Callable[[np.ndarray], np.ndarray],
    Callable[[np.ndarray], np.ndarray],
]:
    """
    Per-window normalizer: divide by the mean of the y-lag window.

    Given the current lag window (1D ndarray in feature order: [y_t, y_{t-1}, ...]),
    returns (transform, inverse_transform) where:
      transform(a)        = a / mean(window)
      inverse_transform(a)= a * mean(window)

    Notes
    -----
    - If the mean is NaN, inf, or ~0, falls back to 1.0 to avoid division by zero.
    - Exogenous X is untouched; this normalizes only the y-derived features/target.

    Parameters
    ----------
    window : np.ndarray
        1D array of lagged y values (most recent first).

    Returns
    -------
    transform : Callable[[np.ndarray], np.ndarray]
    inverse_transform : Callable[[np.ndarray], np.ndarray]
    """
    w = np.asarray(window, dtype=float).ravel()
    mu = float(np.mean(w)) if w.size else 1.0

    # robust fallback if mean is invalid or too close to zero
    if not np.isfinite(mu) or abs(mu) < 1e-12:
        mu = 1.0

    def transform(arr: np.ndarray) -> np.ndarray:
        a = np.asarray(arr, dtype=float).ravel()
        return a / mu

    def inverse_transform(arr: np.ndarray) -> np.ndarray:
        a = np.asarray(arr, dtype=float).ravel()
        return a * mu

    return transform, inverse_transform

model =  ReductionForecaster(
    regressor,
    window_length=30,
    steps_ahead=1,
    normalization_strategy=mean_window_normalizer,
)

model.fit(y_train, X=X_train)
y_pred = model.predict(fh=y_test.index, X=X_test)

```

```{python}
plot_series(
    y_train, y_test, y_pred, labels=["Treino", "Teste", "Previsão com ML + Diferença + Normalização"]
)
```